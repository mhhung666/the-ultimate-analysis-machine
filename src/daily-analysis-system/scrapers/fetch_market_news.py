#!/usr/bin/env python3
"""
Yahoo Finance é‡‘èæ–°èçˆ¬èŸ²å·¥å…·
å¾ Yahoo Finance çˆ¬å–ç‰¹å®šè‚¡ç¥¨çš„æœ€æ–°é‡‘èæ–°è
"""

from datetime import datetime
import yfinance as yf
import json

from common import (
    create_argument_parser,
    setup_output_path,
    write_output,
    print_status,
    print_error,
    validate_positive_int,
    safe_exit,
    generate_dated_filename,
    ScraperError,
)


def format_datetime(date_str):
    """
    å°‡ ISO 8601 æ ¼å¼çš„æ—¥æœŸæ™‚é–“è½‰æ›ç‚ºæ˜“è®€æ ¼å¼

    Args:
        date_str: ISO 8601 æ ¼å¼çš„æ—¥æœŸæ™‚é–“å­—ä¸² (ä¾‹å¦‚: 2025-11-17T21:06:41Z)

    Returns:
        æ ¼å¼åŒ–å¾Œçš„æ—¥æœŸæ™‚é–“å­—ä¸² (ä¾‹å¦‚: Nov 17, 2025 21:06 UTC)
    """
    try:
        dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
        return dt.strftime('%b %d, %Y %H:%M UTC')
    except:
        return date_str


def fetch_market_news(symbol, limit=10, output_file=None, json_output=False, auto_filename=False):
    """
    çˆ¬å–è‚¡ç¥¨ç›¸é—œæ–°è

    Args:
        symbol: è‚¡ç¥¨ä»£ç¢¼ (ä¾‹å¦‚: AAPL, TSLA, NVDA)
        limit: è¦é¡¯ç¤ºçš„æ–°èæ•¸é‡ï¼Œé è¨­10å‰‡
        output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼Œå¦‚æœç‚º None å‰‡æ ¹æ“š auto_filename æ±ºå®š
        json_output: æ˜¯å¦è¼¸å‡ºç‚º JSON æ ¼å¼ï¼Œé è¨­ False (Markdown æ ¼å¼)
        auto_filename: æ˜¯å¦è‡ªå‹•ç”¢ç”Ÿæª”åï¼ˆæ ¼å¼ï¼šSYMBOL-YYYY-MM-DD.mdï¼‰
    """
    print_status(f"æ­£åœ¨çˆ¬å– {symbol} çš„æœ€æ–°æ–°è...")

    # ä½¿ç”¨ yfinance çˆ¬å–æ–°è
    ticker = yf.Ticker(symbol)
    news = ticker.news

    if not news:
        print_error("ç„¡æ³•å–å¾—æ–°èè³‡æ–™")
        return False

    # é™åˆ¶æ–°èæ•¸é‡
    news = news[:limit]

    print_status(f"æ‰¾åˆ° {len(news)} å‰‡æ–°è")

    # æ ¼å¼åŒ–è¼¸å‡º
    if json_output:
        # JSON æ ¼å¼è¼¸å‡º
        output_data = []
        for article in news:
            content = article.get('content', {})
            output_data.append({
                'id': content.get('id'),
                'title': content.get('title'),
                'summary': content.get('summary'),
                'publisher': content.get('provider', {}).get('displayName'),
                'published_at': content.get('pubDate'),
                'url': content.get('canonicalUrl', {}).get('url'),
                'content_type': content.get('contentType')
            })

        result = json.dumps(output_data, indent=2, ensure_ascii=False)
    else:
        # Markdown æ ¼å¼è¼¸å‡º
        output_lines = []
        output_lines.append(f"# {symbol} æœ€æ–°é‡‘èæ–°è\n")
        output_lines.append(f"**æ›´æ–°æ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        output_lines.append(f"**æ–°èæ•¸é‡**: {len(news)} å‰‡\n")
        output_lines.append("---\n")

        for i, article in enumerate(news, 1):
            content = article.get('content', {})

            # æå–è³‡è¨Š
            title = content.get('title', 'N/A')
            summary = content.get('summary', 'N/A')
            pub_date = content.get('pubDate', 'N/A')
            provider = content.get('provider', {}).get('displayName', 'N/A')
            url = content.get('canonicalUrl', {}).get('url', '#')
            content_type = content.get('contentType', 'ARTICLE')

            # æ ¼å¼åŒ–æ—¥æœŸ
            formatted_date = format_datetime(pub_date) if pub_date != 'N/A' else 'N/A'

            # æ–°èé¡å‹åœ–ç¤º
            type_icon = "ğŸ¥" if content_type == "VIDEO" else "ğŸ“°"

            # çµ„åˆè¼¸å‡º
            output_lines.append(f"## {i}. {type_icon} {title}\n")
            output_lines.append(f"**ä¾†æº**: {provider}  ")
            output_lines.append(f"**ç™¼å¸ƒæ™‚é–“**: {formatted_date}  ")
            output_lines.append(f"**é€£çµ**: [{url}]({url})\n")
            output_lines.append(f"**æ‘˜è¦**:  ")
            output_lines.append(f"{summary}\n")
            output_lines.append("---\n")

        result = '\n'.join(output_lines)

    # æ±ºå®šè¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    if output_file:
        final_output = output_file
    elif auto_filename:
        # è‡ªå‹•ç”¢ç”Ÿæª”åï¼ˆæ ¼å¼ï¼šSYMBOL-YYYY-MM-DD.md æˆ– .jsonï¼‰
        extension = 'json' if json_output else 'md'
        filename = generate_dated_filename(symbol, extension)
        final_output = setup_output_path(
            output_arg=filename,
            default_filename=filename,
            default_subdir="News",
            use_stdout=False
        )
    else:
        final_output = None

    # è¼¸å‡ºçµæœ
    return write_output(result, final_output, verbose=True)


def main():
    parser = create_argument_parser(
        description='çˆ¬å– Yahoo Finance è‚¡ç¥¨ç›¸é—œæ–°èï¼ˆé è¨­è¼¸å‡º data/market-data/{YEAR}/News/SYMBOL-YYYY-MM-DD.mdï¼‰',
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  # çˆ¬å– Apple çš„æœ€æ–°æ–°è (é è¨­10å‰‡ï¼Œè‡ªå‹•ç”¢ç”Ÿæª”å)
  python fetch_market_news.py AAPL

  # çˆ¬å– Tesla çš„æœ€æ–°5å‰‡æ–°èä¸¦å„²å­˜ç‚º Markdown
  python fetch_market_news.py TSLA -l 5

  # æŒ‡å®šè¼¸å‡ºæª”æ¡ˆ
  python fetch_market_news.py NVDA -o data/market-data/2025/News/NVDA-2025-11-18.md

  # çˆ¬å–å¤šå®¶å…¬å¸çš„æ–°èï¼ˆæœƒè‡ªå‹•ç”¢ç”Ÿå¸¶æ—¥æœŸçš„æª”åï¼‰
  python fetch_market_news.py AAPL
  python fetch_market_news.py MSFT

å¸¸ç”¨è‚¡ç¥¨ä»£ç¢¼:
  ç§‘æŠ€è‚¡: AAPL (Apple), TSLA (Tesla), NVDA (Nvidia), MSFT (Microsoft), GOOGL (Google)
  é‡‘èè‚¡: JPM (JP Morgan), BAC (Bank of America), GS (Goldman Sachs)
  å…¶ä»–: UPS, AMZN (Amazon), META (Meta/Facebook)
        """
    )

    parser.add_argument(
        'symbol',
        type=str,
        help='è‚¡ç¥¨ä»£ç¢¼ (ä¾‹å¦‚: AAPL, TSLA, NVDA)'
    )

    parser.add_argument(
        '-l', '--limit',
        type=int,
        default=10,
        help='è¦é¡¯ç¤ºçš„æ–°èæ•¸é‡ (é è¨­: 10å‰‡)'
    )

    parser.add_argument(
        '-o', '--output',
        type=str,
        help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ (è‹¥æœªæŒ‡å®šå‰‡è‡ªå‹•ç”¢ç”Ÿå¸¶æ—¥æœŸçš„æª”å)'
    )

    parser.add_argument(
        '--json',
        action='store_true',
        help='è¼¸å‡ºç‚º JSON æ ¼å¼ (é è¨­ç‚º Markdown æ ¼å¼)'
    )

    parser.add_argument(
        '--stdout',
        action='store_true',
        help='è¼¸å‡ºåˆ°è¢å¹•è€Œéæª”æ¡ˆ'
    )

    args = parser.parse_args()

    # æª¢æŸ¥åƒæ•¸
    try:
        validate_positive_int(args.limit, "æ–°èæ•¸é‡")
    except ScraperError as e:
        print_error(str(e))
        safe_exit(False)

    # æ±ºå®šæ˜¯å¦ä½¿ç”¨è‡ªå‹•æª”å
    # å¦‚æœæœ‰æŒ‡å®š -o æˆ– --stdoutï¼Œå‰‡ä¸ä½¿ç”¨è‡ªå‹•æª”å
    auto_filename = not args.output and not args.stdout

    # åŸ·è¡Œçˆ¬èŸ²
    success = fetch_market_news(
        symbol=args.symbol,
        limit=args.limit,
        output_file=args.output,
        json_output=args.json,
        auto_filename=auto_filename
    )

    safe_exit(success)


if __name__ == '__main__':
    main()
